{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import cm,colors,rc\n",
    "import random\n",
    "import warnings\n",
    "import cv2\n",
    "from IPython import display\n",
    "from IPython.display import HTML\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import keras.utils as utils\n",
    "import progressbar\n",
    "import imageio\n",
    " \n",
    "%matplotlib inline\n",
    "rc('figure',figsize=(15,5))\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function for face alignment\n",
    "\n",
    "import dlib\n",
    "from sklearn.ensemble import IsolationForest\n",
    " \n",
    "def face_data_normalizer(images_directory_input, \n",
    "                         images_directory_output, \n",
    "                         output_size=256, \n",
    "                         align_faces=True, \n",
    "                         limit_num_faces=None,\n",
    "                         limit_num_files=None):\n",
    "    \n",
    "    def write_faces_to_disk(directory, faces):\n",
    "        print(\"writing faces to disk...\")\n",
    "        if os.path.exists(directory):\n",
    "            shutil.rmtree(directory)\n",
    "        print('creating output directory: %s'%(directory))\n",
    "        os.mkdir(directory)\n",
    "        for i in range(faces.shape[0]):\n",
    "            cv2.imwrite(''.join([directory,\"%03d.jpg\"%i]),faces[i,:,:,::-1])\n",
    "        print(\"wrote %d faces\"%(faces.shape[0]))\n",
    "     \n",
    "    if images_directory_input[-1] != '/':\n",
    "        images_directory_input += '/'\n",
    "    if images_directory_output[-1] != '/':\n",
    "        images_directory_output += '/'\n",
    " \n",
    "    faces = []\n",
    " \n",
    "    if os.path.exists(images_directory_output):\n",
    "        print('data already preprocessed? loading preprocessed files...')\n",
    "        for img_idx,img_file in enumerate(os.listdir(images_directory_output)):\n",
    "            # load the input image, resize it, and convert it to grayscale\n",
    "            image = cv2.imread(''.join([images_directory_output,img_file]))\n",
    "            if image is None: continue\n",
    "            image = image[:,:,::-1] #BGR to RGB\n",
    "            faces.append(np.expand_dims(image,0))\n",
    "        faces = np.asarray(faces)\n",
    "        print('loaded %d preprocessed images'%(faces.shape[0]))\n",
    "        if remove_outliers_:\n",
    "            faces,num_outliers = remove_outliers(faces)\n",
    "        write_faces_to_disk(images_directory_output,faces)\n",
    "        return faces\n",
    "     \n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "         \n",
    "    max_val = len(os.listdir(images_directory_input)) if limit_num_files is None else limit_num_files\n",
    "    pb = display.ProgressBar(max_val)\n",
    "    pb.display()\n",
    "         \n",
    "    face_counter = 0\n",
    "    for img_idx,img_file in enumerate(os.listdir(images_directory_input)):\n",
    "        # load the input image, resize it, and convert it to grayscale\n",
    "        image = cv2.imread(''.join([images_directory_input,img_file]))\n",
    " \n",
    "        if image is None:\n",
    "            continue\n",
    " \n",
    "        image = image[:,:,::-1] #BGR to RGB\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "        # detect faces in the grayscale image\n",
    "        rects = detector(gray, 1)\n",
    " \n",
    "        if len(rects) > 0:\n",
    "            # loop over the face detections\n",
    "            for (i, rect) in enumerate(rects):\n",
    "                if align_faces:\n",
    "                    ######### Align with facial features detector #########\n",
    " \n",
    "                    shape = predictor(gray, rect) # get facial features\n",
    "                    shape = np.array([(shape.part(j).x, shape.part(j).y) for j in range(shape.num_parts)])\n",
    " \n",
    "                    # center and scale face around mid point between eyes\n",
    "                    center_eyes = shape[27].astype(np.int)\n",
    "                    eyes_d = np.linalg.norm(shape[36]-shape[45])\n",
    "                    face_size_x = int(eyes_d * 2.)\n",
    "                    if face_size_x < 50: continue\n",
    " \n",
    "                    # rotate to normalized angle\n",
    "                    d = (shape[45] - shape[36]) / eyes_d # normalized eyes-differnce vector (direction)\n",
    "                    a = np.rad2deg(np.arctan2(d[1],d[0])) # angle\n",
    "                    scale_factor = float(output_size) / float(face_size_x * 2.) # scale to fit in output_size\n",
    "                    # rotation (around center_eyes) + scale transform\n",
    "                    M = np.append(cv2.getRotationMatrix2D((center_eyes[0], center_eyes[1]),a,scale_factor),[[0,0,1]], axis=0)\n",
    "                    # apply shift from center_eyes to middle of output_size \n",
    "                    M1 = np.array([[1.,0.,-center_eyes[0]+output_size/2.],\n",
    "                                   [0.,1.,-center_eyes[1]+output_size/2.],\n",
    "                                   [0,0,1.]])\n",
    "                    # concatenate transforms (rotation-scale + translation)\n",
    "                    M = M1.dot(M)[:2]\n",
    "                    # warp\n",
    "                    try:\n",
    "                        face = cv2.warpAffine(image, M, (output_size, output_size), borderMode=cv2.BORDER_REPLICATE)\n",
    "                    except:\n",
    "                        continue\n",
    "                    face_counter += 1\n",
    "                    face = cv2.resize(face,(output_size,output_size))\n",
    "                    faces.append(face)\n",
    "                else:\n",
    "                    ######### \"No align\" with just the detector #########\n",
    "                    if rect.width() < 50: continue\n",
    "                     \n",
    "                    # find scale factor\n",
    "                    scale_factor = float(output_size) / float(rect.width() * 2.) # scale to fit in output_size\n",
    "                     \n",
    "                    # scale around the center of the face (shift a bit for the approximate y-position of the eyes)\n",
    "                    M = np.append(cv2.getRotationMatrix2D((rect.center().x,rect.center().y-rect.height()/6.),0,scale_factor),[[0,0,1]], axis=0)\n",
    "                    # apply shift from center_eyes to middle of output_size \n",
    "                    M1 = np.array([[1.,0.,-rect.center().x+output_size/2.],\n",
    "                                   [0.,1.,-rect.center().y+output_size/2.+rect.height()/6.],\n",
    "                                   [0,0,1.]])\n",
    "                    # concatenate transforms (rotation-scale + translation)\n",
    "                    M = M1.dot(M)[:2]\n",
    "                    try:\n",
    "                        face = cv2.warpAffine(image, M, (output_size, output_size), borderMode=cv2.BORDER_REPLICATE)\n",
    "                    except:\n",
    "                        continue\n",
    "                    face_counter += 1\n",
    " \n",
    "                    faces.append(face)\n",
    "                 \n",
    "        pb.progress = img_idx+1\n",
    "         \n",
    "        if limit_num_faces is not None and faces.shape[0] > limit_num_faces:\n",
    "            break\n",
    "        if limit_num_files is not None and img_idx >= limit_num_files:\n",
    "            break\n",
    " \n",
    "    faces = np.asarray(faces)\n",
    "     \n",
    "    write_faces_to_disk(images_directory_output,faces)\n",
    "     \n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<progress style='width:60ex' max='273' value='273'></progress>"
      ],
      "text/plain": [
       "[============================================================] 273/273"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing faces to disk...\n",
      "creating output directory: aligned/\n",
      "wrote 298 faces\n"
     ]
    }
   ],
   "source": [
    "#align faces\n",
    "\n",
    "if os.path.isdir('aligned'): shutil.rmtree('aligned')\n",
    "faces_noalign = face_data_normalizer('Instagram',\n",
    "                                     'aligned', \n",
    "                                     output_size = 256,\n",
    "                                     align_faces = True, \n",
    "                                     limit_num_files=None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
